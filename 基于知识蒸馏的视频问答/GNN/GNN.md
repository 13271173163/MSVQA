# 图神经网络

## 为什么需要图神经网络？

​	随着机器学习、深度学习的发展，语音、图像自然语言取得了重大突破，然而语音、图像、文本都是很简单的序列或者网格数据，是很结构化的数据，深度学习很善于处理该种类型的数据，然而现实世界中并不是所有的事物都可以表示成一个序列或者一个网格，例如社交网络、知识图谱、复杂的文件系统等，也就是说很多事物都是非结构化的。相比于简单的文本和图像，这种网络类型的非结构化的数据非常复杂，处理它的难点包括：（1）图的大小是任意的，图的拓扑结构复杂，没有像图像一样的空间局部性；（2）图没有固定的节点顺序，或者说没有一个参考节；（3）图经常是动态图，而且包含多模态的特征。

​	补充：非结构化数据：是数据结构不规则或不完整，没有预定义的数据模型，不方便用数据库二维逻辑表来表现的数据。包括所有格式的办公文档、文本、图片、XML, HTML、各类报表、图像和音频/视频信息等。

## 什么是图？哪些数据可以表示成图？    

​	图表示实体（entity）之间的一些关系。实体就是点，关系就是边。图分为有向图和无向图。为了进一步描述每个节点（V）、边（E）或整个图（U），我们可以将信息存储在图的每个部件中，如节点、边，并用向量进行表示。GNN关注的重点就在于如何将想要的信息表示为向量，已经这些向量如何通过数据进行学习。
![2de44a58b6784e63ac47b8c2799ca927](C:\Users\zhangwenchao\Desktop\学习\大创项目\基于知识蒸馏的视频问答\GNN\GNN图片\2de44a58b6784e63ac47b8c2799ca927.png)

​	下图展示了GNN如何通过网络层从其周围的节点收集信息：

![ede0dc0e23bf46c682a25b991bdafd6c](C:\Users\zhangwenchao\Desktop\学习\大创项目\基于知识蒸馏的视频问答\GNN\GNN图片\ede0dc0e23bf46c682a25b991bdafd6c.png)

可以表示成图的一些数据：

1. 文本
2. 图像
3. 分子图：原子为节点，键为边
4. 社交网络
5. 文章引用
6. 网页连接（有向图），机器学习模型、编程代码、数学方程式等也可以表示为图，其中变量是点，边则是将这些变量作为输入和输出的操作。

​	**总结：从上面的例子可以得出，输入到GNN中的一个图包含四个部分，一个节点的特征矩阵，一个边的特征矩阵，一个点连接情况的邻接矩阵以及一个全局信息。**

## 使用GNN最终要达到的目标是什么？

 图上的预测任务通常分为三种类型：图级、节点级和边级。

1. 在图级任务中，我们的目标是预测整个图的属性。
2. 在节点级任务中：涉及预测图中每个节点的身份或角色。
3. 在边级任务中：GNN模型可用于预测节点之间的关系（即每条边的信息）。

## GNN网络结构

### （1）最简单的GNN

​	 在该GNN的一层中： 对节点向量、边向量和全局向量分别构造一个多层感知机（MLP）（或者可微分方程），这三个MLP就共同组成了一个GNN的层。图是输入，每个组件 (V,E,U) 都由 MLP 更新以生成新图。每个函数下标表示 GNN 模型第 n 层的不同图形属性的单独函数。

![e3fcc773c7a0453a8b7d115b19b698c2](C:\Users\zhangwenchao\Desktop\学习\大创项目\基于知识蒸馏的视频问答\GNN\GNN图片\e3fcc773c7a0453a8b7d115b19b698c2.png)

​	其中Un代表全局信息，Vn代表所有的节点，En代表所有的边，每个f（带有下标）就是一个多层感知机，由这些共同组成了GNN的一层。多层这样的结构堆叠在一起就构成了一个最简单的[图神经网络](https://so.csdn.net/so/search?q=图神经网络&spm=1001.2101.3001.7020)。

### （2）通过合并信息进行GNN预测

​	我们已经构建了一个简单的 GNN，但是我们如何在上述任何任务中进行预测？**如果要求对节点进行二元预测，并且图形已经包含节点信息，则方法很简单——对于每个节点嵌入，应用线性分类器（或者若干全连接层）**，就可以对顶点进行预测了。

​	可能将图中的信息存储在边中，但在节点中没有信息，但仍需要对节点进行预测。需要一种方法从边缘收集信息并将它们提供给节点进行预测。可以通过合并做到这一点。合并分两步进行：

1. 第一步，对于要合并的每个项目收集它们的每个嵌入并将它们连接成一个矩阵；
2. 第二步，通过求和运算聚和收集到的嵌入。

​	通俗来讲就是将与该顶点相连接的边的**嵌入求和**（或者其他方式），得到的结果加到顶点嵌入中（如果维度不同需要做映射），如下图展示。这种操作方法叫做**池化（pooling）**。这样经过池化Pooling以后每个顶点中都含有丰富信息，**对于边信息缺失或者全局信息缺失我们采用对称的方法进行处理。**

![d8f22fe25e164499be0efcc249bb6d6c](C:\Users\zhangwenchao\Desktop\学习\大创项目\基于知识蒸馏的视频问答\GNN\GNN图片\d8f22fe25e164499be0efcc249bb6d6c.png)

### （3）边缘特征->二进制节点信息

​	如果我们只有边缘级特征，并试图预测二进制节点信息，我们可以使用池化将信息路由（或传递）到需要去的地方。例如：

![21174be88be24f73be5a0980fe0ec3e2](C:\Users\zhangwenchao\Desktop\学习\大创项目\基于知识蒸馏的视频问答\GNN\GNN图片\21174be88be24f73be5a0980fe0ec3e2.png)

### （4）节点特征->二进制边缘特征

 	如果我们只有节点级特征，并试图预测二进制边缘级信息，则模型如下：

![ab85950a73b045d486f321f7367e032f](C:\Users\zhangwenchao\Desktop\学习\大创项目\基于知识蒸馏的视频问答\GNN\GNN图片\ab85950a73b045d486f321f7367e032f.png)

### （5）节点特征->二进制全局特征

 	如果我们只有节点级别的特征，并且需要预测二进制全局属性，我们需要将所有可用的节点信息收集在一起并聚合它们。例如：

![c90d62720a71474f99dc2db1b3b46173](C:\Users\zhangwenchao\Desktop\学习\大创项目\基于知识蒸馏的视频问答\GNN\GNN图片\c90d62720a71474f99dc2db1b3b46173.png)

### （6）总结

​	可以将最简单的GNN模型总结成如下的结构：一张图输入，经过GNN层（实质上就是三个分别对应点、边和全局的MLP），输出一个属性已经变换的图，在经过全连接层，得到输出。例如：

![59385ee8f0bb4704b51b1db2469a1701](C:\Users\zhangwenchao\Desktop\学习\大创项目\基于知识蒸馏的视频问答\GNN\GNN图片\59385ee8f0bb4704b51b1db2469a1701.png)

​	**这只是最简单的GNN，因为我们没有在GNN层内使用图的连通性信息。 顶点、边和全局信息都是独立处理的，只在最后池化时使用了连通性信息。**  

## 对GNN层进行优化

​	 前面构建的GNN层存在一个缺点，就是每一层GNN层单独地对节点、边、全局信息进行处理，没有利用节点之间的连接信息。

​	GNN的输入有四个部分，节点信息、边信息、全局信息、节点之间的连接信息，但是目前为止，GNN层中只利用了前三种信息。

​	考虑在每一层GNN层中加入池化，让相邻顶点、边、以及全局信息之间进行信息传递，而不是等到最后进行预测的时候才进行池化。

信息传递(或者说池化)包括三个步骤：

1. 对于图中的每个顶点，收集所有相邻顶点或边的信息；
2. 通过聚合函数(如求和)聚合所有收集到的信息；
3. 合并的信息通过一个更新函数传递，通常是一个学习过的神经网络。

​	通过将消息传递 GNN 层堆叠在一起，一个节点最终可以整合来自整个图的信息：在三层之后，一个节点拥有离它三步之遥的节点的信息。例如：

![ede0dc0e23bf46c682a25b991bdafd6c](C:\Users\zhangwenchao\Desktop\学习\大创项目\基于知识蒸馏的视频问答\GNN\GNN图片\ede0dc0e23bf46c682a25b991bdafd6c.png)

​	为了让GNN网络能更好的对图进行预测，提取出图中更加丰富的特征信息，我们不局限于在相邻顶点之间进行消息传递，顶点和边之间，边和边之间，顶点和全局信息之间，以及边和全局信息之间都可以进行消息传递。例如：

![a2c4581600a04fea8ab432985cd1ffda](C:\Users\zhangwenchao\Desktop\学习\大创项目\基于知识蒸馏的视频问答\GNN\GNN图片\a2c4581600a04fea8ab432985cd1ffda.png)

![40f7809cf52744ec8a861e4dcbff454d](C:\Users\zhangwenchao\Desktop\学习\大创项目\基于知识蒸馏的视频问答\GNN\GNN图片\40f7809cf52744ec8a861e4dcbff454d.png)

​	之前的消息传递，只考虑了邻接的顶点和边，如果一个顶点想要聚合距离它很远的顶点和边的信息，怎么办呢？此提出一个虚拟的主节点，它和图中所有的节点和边虚拟地连接，这个主节点的信息就是全局信息U。在节点信息传递给边的时候，也会把U一起传递，把边信息传递给节点的时候，也会把U一起传递；然后更新边和节点后，将边和节点的信息一起汇聚给U，之后做多层感知机更新。
![64991a69b7f0485c80603ad4ef097967](C:\Users\zhangwenchao\Desktop\学习\大创项目\基于知识蒸馏的视频问答\GNN\GNN图片\64991a69b7f0485c80603ad4ef097967.png)

